recipe4_decision_tree_model
all_models_metrics <- bind_rows(
recipe1_lm_reg_model, recipe2_lm_reg_model, recipe1_lasso_reg_model, recipe2_lasso_reg_model,
recipe3_decision_tree_model, recipe4_decision_tree_model
)# Combine all model metrics
all_models_metrics |> arrange(.metric, .estimate)# Arrange the results to compare performance. Sort them to identify the best models --> rmse the smaller the better; mae the smaller the better; rsq the bigger the better.
#| autorun: true
#| startover: false
library(tidyverse)
library(tidymodels)
library(corrplot)
library(janitor)
#| autorun: false
#| completion: true
#| min-lines: 3
ames_clean <- ames |>
clean_names() |>
#clean column name and put everything lowercase thanks to the janitor package
mutate(price_log= log(sale_price ,base = 10),
total_sf= total_bsmt_sf+first_flr_sf+second_flr_sf,
total_bath= bsmt_full_bath+bsmt_half_bath+full_bath+half_bath) |>
# apply manipulations that are needed across multiple models like transforming sale_price and feature engineering to create two important columns
select(-c(sale_price, total_bsmt_sf, first_flr_sf, second_flr_sf,
bsmt_full_bath, bsmt_half_bath, full_bath, half_bath))# remove redundant columns
glimpse(ames_clean)
#| autorun: false
#| completion: true
#| min-lines: 3
correlation_matrix2 <- ames_clean |>
select(price_log, kitchen_abv_gr, tot_rms_abv_grd, fireplaces, garage_cars, garage_area, wood_deck_sf, open_porch_sf, longitude, latitude) |>
cor(use = "complete.obs")
correlation_matrix2
correlation_matrix2 |>
corrplot()
str(ames)
colnames(ames)
colnames(ames_clean)
str(ames_clean)
#| autorun: false
#| completion: true
#| min-lines: 3
ames_clean |>
select(67, 3, 4, 18, 19 , 25, 31, 33, 34, 39:42, 44, 47, 48, 51:56, 60:62, 65,66, 68,69 ) |>
cor(use = "complete.obs")
recipe_3a <- recipe(price_log ~ year_built+ year_remod_add+ gr_liv_area+ garage_cars+ garage_area+  total_sf+ total_bath + overall_cond + neighborhood, data= ames_train) |>
step_normalize(all_numeric_predictors()) |>
step_dummy(all_nominal_predictors())
#| autorun: false
#| completion: true
#| min-lines: 3
# Split the data
set.seed(123)# setting a seed will ensure reproducibility. The number can be any random number as long as you always use the same
ames_split <- initial_split(ames_clean, prop = 0.75) # define the split and its data proportion
ames_train <- training(ames_split) #create a train set
ames_test <- testing(ames_split)#create a test set
?linear_reg
recipe_3a <- recipe(price_log ~ year_built+ year_remod_add+ gr_liv_area+ garage_cars+ garage_area+  total_sf+ total_bath + overall_cond + neighborhood, data= ames_train) |>
step_normalize(all_numeric_predictors()) |>
step_dummy(all_nominal_predictors())
# Ridge regularized linear regression with glmnet
linear_mod_ridge <- linear_reg(penalty = 0.1, mixture = 0) |>
set_engine("glmnet") |>
set_mode("regression")
#| autorun: false
#| completion: true
#| min-lines: 3
recipe3a_predictions_reg <- predict(recipe3a_workflow_reg, new_data = ames_test) |>
bind_cols(ames_test) |> # add original columns
mutate(sale_price= 10^price_log, pred = 10^.pred)# Inverse of log10, easier to interpret the prediction now that are not in a log10 form
#| autorun: false
#| completion: true
#| min-lines: 3
recipe3a_workflow_reg <- workflow() |>
add_recipe(recipe3a)|>
add_model(linear_mod_reg) |>
fit(data = ames_train)
#| autorun: false
#| completion: true
#| min-lines: 3
# Linear regression with lm
linear_mod_reg <- linear_reg() |>
set_engine("lm") |>
set_mode("regression")
#| autorun: false
#| completion: true
#| min-lines: 3
recipe1_workflow_reg <- workflow() |>
add_recipe(recipe1) |>
add_model(linear_mod_reg) |>
fit(data = ames_train)#we create and fit the workflow on just the train set
#| autorun: false
#| completion: true
#| min-lines: 3
recipe1 <- recipe(price_log ~ total_sf + total_bath, data = ames_train) |>
step_normalize(all_numeric_predictors())# regression model with 2 variables
recipe2 <- recipe(price_log ~ ., data = ames_train) |>
step_normalize(all_numeric_predictors()) |>
step_dummy(all_nominal_predictors())
#| autorun: false
#| completion: true
#| min-lines: 3
# Making predictions for the linear regression models workflows
recipe1_predictions_reg <- predict(recipe1_workflow_reg, new_data = ames_test) |> # making the prediction on test data (unseen data)
bind_cols(ames_test) |> # add original columns
mutate(sale_price= 10^price_log, pred = 10^.pred)  # Inverse of log10, easier to interpret the prediction now that are not in a log10 form
#| autorun: true
#| startover: false
library(tidyverse)
library(tidymodels)
library(corrplot)
library(janitor)
#| autorun: false
#| completion: true
#| min-lines: 3
ames_clean <- ames |>
clean_names() |>
#clean column name and put everything lowercase thanks to the janitor package
mutate(price_log= log(sale_price ,base = 10),
total_sf= total_bsmt_sf+first_flr_sf+second_flr_sf,
total_bath= bsmt_full_bath+bsmt_half_bath+full_bath+half_bath) |>
# apply manipulations that are needed across multiple models like transforming sale_price and feature engineering to create two important columns
select(-c(sale_price, total_bsmt_sf, first_flr_sf, second_flr_sf,
bsmt_full_bath, bsmt_half_bath, full_bath, half_bath))# remove redundant columns
glimpse(ames_clean)
#| autorun: false
#| completion: true
#| min-lines: 3
correlation_matrix <- ames_clean |>
select(4, 18, 40, 47, 67:69 ) |>
cor(use = "complete.obs")# exploring correlation is a great step to identify those variables that seem to have a relation between each other and with your dependent variable.
#?cor
correlation_matrix |>
corrplot()# visualizing the matrix make it is easier and more accessible to check correlation between variables. It is easy to create this visual thanks to the corrplot package
#| autorun: false
#| completion: true
#| min-lines: 3
correlation_matrix2 <- ames_clean |>
select(price_log, kitchen_abv_gr, tot_rms_abv_grd, fireplaces, garage_cars, garage_area, wood_deck_sf, open_porch_sf, longitude, latitude) |>
cor(use = "complete.obs")
#| autorun: false
#| completion: true
#| min-lines: 3
correlation_matrix2 |>
corrplot()
#| autorun: false
#| completion: true
#| min-lines: 3
# Split the data
set.seed(123)# setting a seed will ensure reproducibility. The number can be any random number as long as you always use the same
ames_split <- initial_split(ames_clean, prop = 0.75) # define the split and its data proportion
ames_train <- training(ames_split) #create a train set
ames_test <- testing(ames_split)#create a test set
#| autorun: false
#| completion: true
#| min-lines: 3
set.seed(007)
#| autorun: false
#| completion: true
#| min-lines: 3
ames_split2 <- initial_split(ames_clean, prop = 0.8)
#| autorun: false
#| completion: true
#| min-lines: 3
ames_train2 <- training(ames_split2) #create a train set
ames_test2 <- testing(ames_split2)#create a test set
#| autorun: false
#| completion: true
#| min-lines: 3
recipe1 <- recipe(price_log ~ total_sf + total_bath, data = ames_train) |>
step_normalize(all_numeric_predictors())# regression model with 2 variables
recipe1# Review the recipe steps
recipe2 <- recipe(price_log ~ ., data = ames_train) |>
step_normalize(all_numeric_predictors()) |>
step_dummy(all_nominal_predictors())
recipe2# Review the recipe steps
recipe3 <- recipe(price_log ~ total_sf + total_bath + overall_cond,  data = ames_train)# regression model with 3 variables
recipe3# Review the recipe steps
recipe4 <- recipe(price_log ~ ., data = ames_train)
recipe4# Review the recipe steps
#| autorun: false
#| completion: true
#| min-lines: 3
# Linear regression with lm
linear_mod_reg <- linear_reg() |>
set_engine("lm") |>
set_mode("regression")
#| autorun: false
#| completion: true
#| min-lines: 3
# Lasso regularized linear regression with glmnet
linear_mod_lasso <- linear_reg(penalty = 0.1, mixture = 1) |>
set_engine("glmnet") |>
set_mode("regression")
#| autorun: false
#| completion: true
#| min-lines: 3
decision_tree_mod <- decision_tree() |>
set_engine("rpart") |>
set_mode("regression")
#| autorun: false
#| completion: true
#| min-lines: 3
recipe1_workflow_reg <- workflow() |>
add_recipe(recipe1) |>
add_model(linear_mod_reg) |>
fit(data = ames_train)#we create and fit the workflow on just the train set
recipe1_workflow_reg |>tidy()#check model results
#| autorun: false
#| completion: true
#| min-lines: 3
recipe2_workflow_reg <- workflow() |>
add_recipe(recipe2) |>
add_model(linear_mod_reg) |>
fit(data = ames_train)#we create and fit the workflow on just the train set
recipe2_workflow_reg |> tidy() |>print(n=272)#check model results
#| autorun: false
#| completion: true
#| min-lines: 3
recipe1_workflow_lasso <- workflow() |>
add_recipe(recipe1) |>
add_model(linear_mod_lasso) |>
fit(data = ames_train)#we create and fit the workflow on just the train set
recipe1_workflow_lasso |> tidy()#check model results
#| autorun: false
#| completion: true
#| min-lines: 3
recipe2_workflow_lasso <- workflow() |>
add_recipe(recipe2) |>
add_model(linear_mod_lasso) |>
fit(data = ames_train)#we create and fit the workflow on just the train set
recipe2_workflow_lasso |> tidy() |>print(n=272)#check model results
#| autorun: false
#| completion: true
#| min-lines: 3
# Lasso regularized linear regression with glmnet
linear_mod_lasso <- linear_reg(penalty = 0.1, mixture = 0.8) |>
set_engine("glmnet") |>
set_mode("regression")
#| autorun: false
#| completion: true
#| min-lines: 3
recipe2_workflow_lasso <- workflow() |>
add_recipe(recipe2) |>
add_model(linear_mod_lasso) |>
fit(data = ames_train)#we create and fit the workflow on just the train set
recipe2_workflow_lasso |> tidy() |>print(n=272)#check model results
#| autorun: false
#| completion: true
#| min-lines: 3
recipe1_workflow_lasso <- workflow() |>
add_recipe(recipe1) |>
add_model(linear_mod_lasso) |>
fit(data = ames_train)#we create and fit the workflow on just the train set
recipe1_workflow_lasso |> tidy()#check model results
#| autorun: false
#| completion: true
#| min-lines: 3
recipe2_workflow_lasso <- workflow() |>
add_recipe(recipe2) |>
add_model(linear_mod_lasso) |>
fit(data = ames_train)#we create and fit the workflow on just the train set
recipe2_workflow_lasso |> tidy() |>print(n=272)#check model results
#| autorun: false
#| completion: true
#| min-lines: 3
recipe3_workflow_dt <- workflow() |>
add_recipe(recipe3)|>
add_model(decision_tree_mod) |>
fit(data = ames_train)#we create and fit the workflow on just the train set
recipe3_workflow_dt #check model results
#| autorun: false
#| completion: true
#| min-lines: 3
recipe4_workflow_dt <- workflow() |>
add_recipe(recipe4)|>
add_model(decision_tree_mod) |>
fit(data = ames_train)#we create and fit the workflow on just the train set
recipe4_workflow_dt#check model results
#| autorun: false
#| completion: true
#| min-lines: 3
# Making predictions for the linear regression models workflows
recipe1_predictions_reg <- predict(recipe1_workflow_reg, new_data = ames_test) |> # making the prediction on test data (unseen data)
bind_cols(ames_test) |> # add original columns
mutate(sale_price= 10^price_log, pred = 10^.pred)  # Inverse of log10, easier to interpret the prediction now that are not in a log10 form
recipe1_predictions_reg |>
select(sale_price, pred)#check the prediction on test data against actual value (truth)
#| autorun: false
#| completion: true
#| min-lines: 3
recipe2_predictions_reg <- predict(recipe2_workflow_reg, new_data = ames_test) |>
bind_cols(ames_test) |> # add original columns
mutate(sale_price= 10^price_log, pred = 10^.pred)   # Inverse of log10, easier to interpret the prediction now that are not in a log10 form
recipe2_predictions_reg |>
select(sale_price, pred)#check the prediction on test data against actual value (truth)
#| autorun: false
#| completion: true
#| min-lines: 3
# Making predictions for the lasso models workflows
recipe1_predictions_lasso <- predict(recipe1_workflow_lasso, new_data = ames_test) |>
bind_cols(ames_test) |> # add original columns
mutate(sale_price= 10^price_log, pred = 10^.pred)  # Inverse of log10, easier to interpret the prediction now that are not in a log10 form
recipe1_predictions_lasso |>
select(sale_price, pred) #check the prediction on test data against actual value (truth)
#| autorun: false
#| completion: true
#| min-lines: 3
recipe2_predictions_lasso <- predict(recipe2_workflow_lasso, new_data = ames_test) |>
bind_cols(ames_test) |> # add original columns
mutate(sale_price= 10^price_log, pred = 10^.pred)   # Inverse of log10, easier to interpret the prediction now that are not in a log10 form
recipe2_predictions_lasso |>
select(sale_price, pred)#check the prediction on test data against actual value (truth)
#| autorun: false
#| completion: true
#| min-lines: 3
# Making predictions for the decision tree models workflows
recipe3_predictions_dt <- predict(recipe3_workflow_dt, new_data = ames_test) |>
bind_cols(ames_test) |> # add original columns
mutate(sale_price= 10^price_log, pred = 10^.pred)   # Inverse of log10, easier to interpret the prediction now that are not in a log10 form
recipe3_predictions_dt |>
select(sale_price, pred) #check the prediction on test data against actual value (truth)
predict(recipe3_workflow_dt, new_data = ames_test)
predict(recipe3_workflow_dt, new_data = ames_test) |>
bind_cols(ames_test)
#| autorun: false
#| completion: true
#| min-lines: 3
# Making predictions for the decision tree models workflows
recipe3_predictions_dt <- predict(recipe3_workflow_dt, new_data = ames_test) |>
bind_cols(ames_test) |> # add original columns
mutate(sale_price= 10^price_log, pred = 10^.pred)   # Inverse of log10, easier to interpret the prediction now that are not in a log10 form
recipe3_predictions_dt |>
select(sale_price, pred) #check the prediction on test data against actual value (truth)
#| autorun: false
#| completion: true
#| min-lines: 3
recipe4_predictions_dt <- predict(recipe4_workflow_dt, new_data = ames_test) |>
bind_cols(ames_test) |> # add original columns
mutate(sale_price= 10^price_log, pred = 10^.pred)# Inverse of log10, easier to interpret the prediction now that are not in a log10 form
recipe4_predictions_dt |>
select(sale_price, pred)#check the prediction on test data against actual value (truth)
recipe1_lm_reg_model <- recipe1_predictions_reg |>
metrics(truth = sale_price, estimate = pred) |>
mutate(model= "recipe1_lm_reg_model") # Adding recipe1_reg_model to distinguish with the others models. Remember: rmse the smaller the better; mae the smaller the better; rsq the bigger the better
recipe1_lm_reg_model
recipe2_lm_reg_model <- recipe2_predictions_reg |>
metrics(truth = sale_price, estimate = pred) |>
mutate(model= "recipe2_lm_reg_model") # Adding recipe2_lm_reg_model to distinguish with the others models. Remember: rmse the smaller the better; mae the smaller the better; rsq the bigger the better
recipe2_lm_reg_model
recipe1_lasso_reg_model <- recipe1_predictions_lasso |>
metrics(truth = sale_price, estimate = pred) |>
mutate(model= "recipe1_lasso_reg_model") # Adding recipe1_lasso_reg_model to distinguish with the others models. Remember: rmse the smaller the better; mae the smaller the better; rsq the bigger the better
recipe1_lasso_reg_model
recipe2_lasso_reg_model <- recipe2_predictions_lasso |>
metrics(truth = sale_price, estimate = pred) |>
mutate(model= "recipe2_lasso_reg_model") # Adding recipe2_lasso_reg_model to distinguish with the others models. Remember: rmse the smaller the better; mae the smaller the better; rsq the bigger the better
recipe2_lasso_reg_model
recipe3_decision_tree_model <- recipe3_predictions_dt |>
metrics(truth = sale_price, estimate = pred) |>
mutate(model= "recipe3_decision_tree_model") # Adding recipe3_decision_tree_model to distinguish with the others models. Remember: rmse the smaller the better; mae the smaller the better; rsq the bigger the better
recipe3_decision_tree_model
recipe4_decision_tree_model <- recipe4_predictions_dt |>
metrics(truth = sale_price, estimate = pred) |>
mutate(model= "recipe4_decision_tree_model") # Adding recipe4_decision_tree_model to distinguish with the others models. Remember: rmse the smaller the better; mae the smaller the better; rsq the bigger the better
recipe4_decision_tree_model
all_models_metrics <- bind_rows(
recipe1_lm_reg_model, recipe2_lm_reg_model, recipe1_lasso_reg_model, recipe2_lasso_reg_model,
recipe3_decision_tree_model, recipe4_decision_tree_model
)# Combine all model metrics
all_models_metrics |> arrange(.metric, .estimate)# Arrange the results to compare performance. Sort them to identify the best models --> rmse the smaller the better; mae the smaller the better; rsq the bigger the better.
#| autorun: false
#| completion: true
#| min-lines: 3
ames_clean |>
select(67, 3, 4, 18, 19 , 25, 31, 33, 34, 39:42, 44, 47, 48, 51:56, 60:62, 65,66, 68,69 ) |>
cor(use = "complete.obs")# no need to assign to a new object because I am just checking the correlation values to identify the column that I will retain.
ames_clean |>
select_if(is.numeric)) |>
ames_clean |>
select_if(is.numeric())) |>
ames_clean |>
select_if(is.numeric()) |>
cor(use = "complete.obs")
ames_clean |>
select_if(is.numeric) |>
cor(use = "complete.obs")
recipe_3a <- recipe(price_log ~ year_built+ year_remod_add+ gr_liv_area+ garage_cars+ garage_area+  total_sf+ total_bath + overall_cond + neighborhood, data= ames_train) |>
step_normalize(all_numeric_predictors()) |>
step_dummy(all_nominal_predictors())
# Ridge regularized linear regression with glmnet
linear_mod_ridge <- linear_reg(penalty = 0.1, mixture = 0) |>
set_engine("glmnet") |>
set_mode("regression")
#| autorun: false
#| completion: true
#| min-lines: 3
recipe3a_workflow_reg <- workflow() |>
add_recipe(recipe3a)|>
add_model(linear_mod_reg) |>
fit(data = ames_train)
recipe_3a <- recipe(price_log ~ year_built+ year_remod_add+ gr_liv_area+ garage_cars+ garage_area+  total_sf+ total_bath + overall_cond + neighborhood, data= ames_train) |>
step_normalize(all_numeric_predictors()) |>
step_dummy(all_nominal_predictors())
# Ridge regularized linear regression with glmnet
linear_mod_ridge <- linear_reg(penalty = 0.1, mixture = 0) |>
set_engine("glmnet") |>
set_mode("regression")
#| autorun: false
#| completion: true
#| min-lines: 3
recipe3a_workflow_reg <- workflow() |>
add_recipe(recipe3a)|>
add_model(linear_mod_reg) |>
fit(data = ames_train)
recipe_3a <- recipe(price_log ~ year_built+ year_remod_add+ gr_liv_area+ garage_cars+ garage_area+  total_sf+ total_bath + overall_cond + neighborhood, data= ames_train) |>
step_normalize(all_numeric_predictors()) |>
step_dummy(all_nominal_predictors())
recipe_3a
#| autorun: false
#| completion: true
#| min-lines: 3
recipe3a_workflow_reg <- workflow() |>
add_recipe(recipe_3a)|>
add_model(linear_mod_reg) |>
fit(data = ames_train)
recipe3a_workflow_reg
recipe3a_workflow_lasso <- workflow() |>
add_recipe(recipe_3a)|>
add_model(linear_mod_lasso) |>
fit(data = ames_train)
recipe3a_workflow_lasso
recipe1_workflow_ridge <- workflow() |>
add_recipe(recipe1)|>
add_model(linear_mod_ridge) |>
fit(data = ames_train)
recipe1_workflow_ridge
recipe2_workflow_ridge  <- workflow() |>
add_recipe(recipe2)|>
add_model(linear_mod_ridge) |>
fit(data = ames_train)
recipe2_workflow_ridge
recipe3a_workflow_ridge <- workflow() |>
add_recipe(recipe3a)|>
add_model(linear_mod_ridge) |>
fit(data = ames_train)
recipe3a_workflow_ridge <- workflow() |>
add_recipe(recipe_3a)|>
add_model(linear_mod_ridge) |>
fit(data = ames_train)
recipe3a_workflow_ridge
#| autorun: false
#| completion: true
#| min-lines: 3
recipe3a_predictions_reg <- predict(recipe3a_workflow_reg, new_data = ames_test) |>
bind_cols(ames_test) |> # add original columns
mutate(sale_price= 10^price_log, pred = 10^.pred)# Inverse of log10, easier to interpret the prediction now that are not in a log10 form
recipe3a_predictions_lasso <- predict(recipe3a_workflow_lasso, new_data = ames_test) |>
bind_cols(ames_test) |>
mutate(sale_price= 10^price_log, pred = 10^.pred)
# Ridge regularized linear regression with glmnet
linear_mod_ridge <- linear_reg(penalty = 0.1, mixture = 0) |>
set_engine("glmnet") |>
set_mode("regression")
recipe1_workflow_ridge <- workflow() |>
add_recipe(recipe1)|>
add_model(linear_mod_ridge) |>
fit(data = ames_train)
recipe1_workflow_ridge
recipe2_workflow_ridge  <- workflow() |>
add_recipe(recipe2)|>
add_model(linear_mod_ridge) |>
fit(data = ames_train)
recipe2_workflow_ridge
recipe3a_workflow_ridge <- workflow() |>
add_recipe(recipe_3a)|>
add_model(linear_mod_ridge) |>
fit(data = ames_train)
recipe3a_workflow_ridge
recipe1_predictions_ridge <- predict(recipe1_workflow_ridge, new_data = ames_test) |>
bind_cols(ames_test) |>
mutate(sale_price= 10^price_log, pred = 10^.pred)
recipe1_predictions_ridge
recipe2_predictions_ridge <- predict(recipe2_workflow_ridge, new_data = ames_test) |>
bind_cols(ames_test) |>
mutate(sale_price= 10^price_log, pred = 10^.pred)
recipe3a_predictions_ridge <- predict(recipe3a_workflow_ridge, new_data = ames_test) |>
bind_cols(ames_test) |>
mutate(sale_price= 10^price_log, pred = 10^.pred)
recipe1_ridge_reg_model <- recipe1_predictions_ridge |>
metrics(truth = sale_price, estimate = pred) |>
mutate(model= "recipe1_ridge_reg_model")
recipe3a_linear_reg_model <- recipe3a_predictions_reg |>
metrics(truth = sale_price, estimate = pred) |>
mutate(model= "recipe3a_linear_reg_model")
recipe3a_lasso_reg_model <- recipe3a_predictions_lasso |>
metrics(truth = sale_price, estimate = pred) |>
mutate(model= "recipe3a_lasso_reg_model")
recipe2_ridge_reg_model <- recipe2_predictions_ridge |>
metrics(truth = sale_price, estimate = pred) |>
mutate(model= "recipe2_ridge_reg_model")
recipe3a_ridge_reg_model <- recipe3a_predictions_ridge |>
metrics(truth = sale_price, estimate = pred) |>
mutate(model= "recipe3a_ridge_reg_model")
activity3e_all_models_metrics <- bind_rows(all_models_metrics,
recipe3a_linear_reg_model, recipe3a_lasso_reg_model, recipe1_ridge_reg_model, recipe2_ridge_reg_model,
recipe3a_ridge_reg_model
)# Combine all model metrics
activity3e_all_models_metrics |> arrange(.metric, .estimate)
activity3e_all_models_metrics |> arrange(.metric, .estimate) |> print(n=33)
#| autorun: true
#| startover: false
help()
